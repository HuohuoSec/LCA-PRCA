{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cch/.conda/envs/cch_TFE_GNN/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "torch.cuda.is_available()  # 如果返回True，说明PyTorch可以看到GPU\n",
    "torch.cuda.device_count()  # 返回GPU的数量\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import os\n",
    "import json\n",
    "import psutil\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "# # 获取当前进程，设置进程亲和性（假设你想使用CPU 17）\n",
    "p = psutil.Process(os.getpid())\n",
    "p.cpu_affinity([17])\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def stringtomd5(originstr):\n",
    "    originstr = originstr.encode(\"utf-8\")\n",
    "    signaturemd5 = hashlib.sha256()\n",
    "    signaturemd5.update(originstr)\n",
    "    return signaturemd5.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>actorID</th>\n",
       "      <th>hostname</th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>objectID</th>\n",
       "      <th>pid</th>\n",
       "      <th>ppid</th>\n",
       "      <th>principal</th>\n",
       "      <th>properties</th>\n",
       "      <th>tid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>actorname</th>\n",
       "      <th>objectname</th>\n",
       "      <th>phrase</th>\n",
       "      <th>command_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inbound</td>\n",
       "      <td>0779a248-9269-498e-8ef7-6bbef00e4e03</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>b788899e-52cc-4d6a-9a6f-cc07b5efa8f3</td>\n",
       "      <td>FLOW</td>\n",
       "      <td>ab16baa4-8596-4143-b018-a2d79a8bbaa0</td>\n",
       "      <td>2276</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '4', 'dest_ip': '225.0.0.1', ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:11:58</td>\n",
       "      <td>python.exe</td>\n",
       "      <td>225.0.0.1-5000</td>\n",
       "      <td>[python.exe, inbound, 225.0.0.1-5000]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inbound</td>\n",
       "      <td>bde3d89a-41f5-498d-aad7-785c9eb41970</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>da1228f7-5b2a-4d36-b9e7-fb1f2842349e</td>\n",
       "      <td>FLOW</td>\n",
       "      <td>d983dccd-cdb2-45ea-a0ec-cd016e758459</td>\n",
       "      <td>860</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '4', 'dest_ip': '224.0.0.251'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:12:00</td>\n",
       "      <td>svchost.exe</td>\n",
       "      <td>224.0.0.251-5353</td>\n",
       "      <td>[svchost.exe, inbound, 224.0.0.251-5353]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inbound</td>\n",
       "      <td>bde3d89a-41f5-498d-aad7-785c9eb41970</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>7d31af23-41bb-4f5c-94f2-fa24924232c8</td>\n",
       "      <td>FLOW</td>\n",
       "      <td>7ed7e83e-e5c2-42bd-8de8-2a70380103dc</td>\n",
       "      <td>860</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '4', 'dest_ip': '224.0.0.251'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:12:00</td>\n",
       "      <td>svchost.exe</td>\n",
       "      <td>224.0.0.251-5353</td>\n",
       "      <td>[svchost.exe, inbound, 224.0.0.251-5353]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inbound</td>\n",
       "      <td>bde3d89a-41f5-498d-aad7-785c9eb41970</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>b9d1fd78-7b2c-4a09-ac7e-e8d548567e9f</td>\n",
       "      <td>FLOW</td>\n",
       "      <td>15ba2aad-3967-45b0-bcc2-98d6b95bbdbf</td>\n",
       "      <td>860</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '4', 'dest_ip': '224.0.0.251'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:12:00</td>\n",
       "      <td>svchost.exe</td>\n",
       "      <td>224.0.0.251-5353</td>\n",
       "      <td>[svchost.exe, inbound, 224.0.0.251-5353]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inbound</td>\n",
       "      <td>bde3d89a-41f5-498d-aad7-785c9eb41970</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>12f298a8-cf2b-4883-a47b-23840c26ba6b</td>\n",
       "      <td>FLOW</td>\n",
       "      <td>b6c337af-537b-4127-abe1-aec51f185d69</td>\n",
       "      <td>860</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '4', 'dest_ip': '224.0.0.251'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:12:00</td>\n",
       "      <td>svchost.exe</td>\n",
       "      <td>224.0.0.251-5353</td>\n",
       "      <td>[svchost.exe, inbound, 224.0.0.251-5353]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    action                               actorID                    hostname  \\\n",
       "0  inbound  0779a248-9269-498e-8ef7-6bbef00e4e03  SysClient0501.systemia.com   \n",
       "1  inbound  bde3d89a-41f5-498d-aad7-785c9eb41970  SysClient0501.systemia.com   \n",
       "2  inbound  bde3d89a-41f5-498d-aad7-785c9eb41970  SysClient0501.systemia.com   \n",
       "3  inbound  bde3d89a-41f5-498d-aad7-785c9eb41970  SysClient0501.systemia.com   \n",
       "4  inbound  bde3d89a-41f5-498d-aad7-785c9eb41970  SysClient0501.systemia.com   \n",
       "\n",
       "                                     id object  \\\n",
       "0  b788899e-52cc-4d6a-9a6f-cc07b5efa8f3   FLOW   \n",
       "1  da1228f7-5b2a-4d36-b9e7-fb1f2842349e   FLOW   \n",
       "2  7d31af23-41bb-4f5c-94f2-fa24924232c8   FLOW   \n",
       "3  b9d1fd78-7b2c-4a09-ac7e-e8d548567e9f   FLOW   \n",
       "4  12f298a8-cf2b-4883-a47b-23840c26ba6b   FLOW   \n",
       "\n",
       "                               objectID   pid  ppid principal  \\\n",
       "0  ab16baa4-8596-4143-b018-a2d79a8bbaa0  2276    -1             \n",
       "1  d983dccd-cdb2-45ea-a0ec-cd016e758459   860    -1             \n",
       "2  7ed7e83e-e5c2-42bd-8de8-2a70380103dc   860    -1             \n",
       "3  15ba2aad-3967-45b0-bcc2-98d6b95bbdbf   860    -1             \n",
       "4  b6c337af-537b-4127-abe1-aec51f185d69   860    -1             \n",
       "\n",
       "                                          properties  tid           timestamp  \\\n",
       "0  {'acuity_level': '4', 'dest_ip': '225.0.0.1', ...   -1 2019-09-19 17:11:58   \n",
       "1  {'acuity_level': '4', 'dest_ip': '224.0.0.251'...   -1 2019-09-19 17:12:00   \n",
       "2  {'acuity_level': '4', 'dest_ip': '224.0.0.251'...   -1 2019-09-19 17:12:00   \n",
       "3  {'acuity_level': '4', 'dest_ip': '224.0.0.251'...   -1 2019-09-19 17:12:00   \n",
       "4  {'acuity_level': '4', 'dest_ip': '224.0.0.251'...   -1 2019-09-19 17:12:00   \n",
       "\n",
       "     actorname        objectname                                    phrase  \\\n",
       "0   python.exe    225.0.0.1-5000     [python.exe, inbound, 225.0.0.1-5000]   \n",
       "1  svchost.exe  224.0.0.251-5353  [svchost.exe, inbound, 224.0.0.251-5353]   \n",
       "2  svchost.exe  224.0.0.251-5353  [svchost.exe, inbound, 224.0.0.251-5353]   \n",
       "3  svchost.exe  224.0.0.251-5353  [svchost.exe, inbound, 224.0.0.251-5353]   \n",
       "4  svchost.exe  224.0.0.251-5353  [svchost.exe, inbound, 224.0.0.251-5353]   \n",
       "\n",
       "  command_line  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# /home/cch/TraceSentinel/data/optc/benign/20-23Sep19/concat_SysClient0051.systemia.com.txt\n",
    "with open(\"../data/optc/benign/20-23Sep19/benign_SysClient0501.systemia.com.txt\", 'r') as file:\n",
    "    content = [json.loads(line) for line in file]\n",
    "\n",
    "\n",
    "\n",
    "def Extract_Semantic_Info(event):\n",
    "    object_type = event['object']\n",
    "    properties = event['properties']\n",
    "\n",
    "    label_mapping = {\n",
    "        \"PROCESS\": ('parent_image_path', 'image_path'),\n",
    "        \"FILE\": ('image_path', 'file_path'),\n",
    "        \"FLOW\": ('image_path', 'dest_ip', 'dest_port', 'direction'),\n",
    "        'MODULE': ('image_path', 'module_path')\n",
    "    }\n",
    "\n",
    "    label_keys = label_mapping.get(object_type, None)\n",
    "    if label_keys:\n",
    "        labels = [properties.get(key) for key in label_keys]\n",
    "        # print(labels)\n",
    "        if all(labels):\n",
    "            if object_type==\"PROCESS\":\n",
    "                event[\"actorname\"], event[\"objectname\"] = labels[0], labels[1]\n",
    "                event[\"command_line\"] = properties.get(\"command_line\", \"None\")\n",
    "                # event[\"command_line\"] = properties.get(\"command_line\", \"None\") if len(properties.get(\"command_line\", \"None\")) > 70 else properties.get(\"command_line\", \"None\")\n",
    "                # event[\"command_line\"] = labels[2] if len(labels[2]) > 70 else labels[2]\n",
    "            elif object_type==\"FILE\":\n",
    "                event[\"actorname\"], event[\"objectname\"] = labels[0], labels[1]\n",
    "            elif object_type==\"FLOW\":\n",
    "                event[\"actorname\"], event[\"objectname\"] = labels[0], '-'.join(labels[1:3])\n",
    "                event['action'] = labels[3]\n",
    "            elif object_type == \"MODULE\":\n",
    "                event[\"actorname\"], event[\"objectname\"] = labels[0], labels[1]\n",
    "            else:\n",
    "                pass\n",
    "            return event\n",
    "    return None\n",
    "\n",
    "\n",
    "def Sentence_Construction(entry):\n",
    "    action = entry[\"action\"]\n",
    "    properties = entry['properties']\n",
    "    object_type = entry['object']\n",
    "    phrase=[]\n",
    "    try:\n",
    "        if object_type==\"PROCESS\":\n",
    "            phrase.append(properties.get(\"parent_image_path\", \"N/A\"))\n",
    "            phrase.append(action)\n",
    "            phrase.append(properties.get(\"image_path\", \"N/A\"))\n",
    "            phrase.append(properties.get(\"command_line\", \"N/A\"))\n",
    "        elif object_type==\"FILE\":\n",
    "            phrase.append(properties.get(\"image_path\", \"N/A\"))\n",
    "            phrase.append(action)\n",
    "            phrase.append(properties.get(\"file_path\", \"N/A\"))\n",
    "        elif object_type==\"FLOW\":\n",
    "            phrase.append(properties.get(\"image_path\", \"N/A\"))\n",
    "            phrase.append(action)\n",
    "            dest_ip = str(properties.get(\"dest_ip\", \"N/A\"))\n",
    "            dest_port = str(properties.get(\"dest_port\", \"N/A\"))\n",
    "            phrase.append(dest_ip+'-'+dest_port)\n",
    "            # phrase.append(properties.get(\"src_ip\", \"N/A\"))\n",
    "            # phrase.append(properties.get(\"src_port\", \"N/A\"))\n",
    "            # phrase.append(properties.get(\"dest_ip\", \"N/A\"))\n",
    "            # phrase.append(properties.get(\"dest_port\", \"N/A\"))\n",
    "            # phrase.append(properties.get(\"direction\", \"N/A\"))\n",
    "        elif object_type==\"MODULE\":\n",
    "            phrase.append(properties.get(\"image_path\", \"N/A\"))\n",
    "            phrase.append(action)\n",
    "            phrase.append(properties.get(\"module_path\", \"N/A\"))\n",
    "        else:\n",
    "            pass\n",
    "    except KeyError:\n",
    "        phrase = []\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def is_valid_entry(entry):\n",
    "    valid_objects = {'PROCESS', 'FILE', 'FLOW', 'MODULE'}\n",
    "    invalid_actions = {'START', 'TERMINATE', 'OPEN'}\n",
    "\n",
    "    object_valid = entry['object'] in valid_objects\n",
    "    action_valid = entry['action'] not in invalid_actions\n",
    "    actor_object_different = entry['actorID'] != entry['objectID']\n",
    "\n",
    "    return object_valid and action_valid and actor_object_different\n",
    "\n",
    "def Traversal_Rules(data):\n",
    "    filtered_data = []\n",
    "\n",
    "    for entry in data:\n",
    "        if is_valid_entry(entry):\n",
    "            filtered_data.append(entry)\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def transform(text):\n",
    "    labeled_data = [event for event in (Extract_Semantic_Info(x) for x in text) if event]\n",
    "    data = Traversal_Rules(labeled_data)\n",
    "\n",
    "\n",
    "    phrases = [Sentence_Construction(x) for x in data if Sentence_Construction(x)]\n",
    "    for datum, phrase in zip(data, phrases):\n",
    "        datum['phrase'] = phrase\n",
    "\n",
    "    # data = sorted(data, key=lambda x: x.get('timestamp'))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'].str[:19], format='%Y-%m-%dT%H:%M:%S')\n",
    "    df.sort_values(by='timestamp', inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = transform(content)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proprocess_df(df):\n",
    "    # 指定列转换为小写\n",
    "    columns_to_lower = ['action', 'object', 'actorname', 'objectname', 'command_line', 'phrase']\n",
    "    # df[columns_to_lower] = df[columns_to_lower].applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    # 使用apply和lambda函数转换列中的值\n",
    "    df[columns_to_lower] = df[columns_to_lower].applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    # 对'phrase'列中的每个元素（列表中的字符串）应用小写转换\n",
    "    df['phrase'] = df['phrase'].apply(lambda x: [item.lower() if isinstance(item, str) else item for item in x])\n",
    "\n",
    "    node2name = {}\n",
    "    # 首先遍历create事件，提取进程名\n",
    "    extract_process_name = df[(df['object'] == 'process') & (df['action'] == 'create')]\n",
    "    for row in extract_process_name.itertuples():\n",
    "        nodeid = row.objectID\n",
    "        processname = row.objectname\n",
    "        if nodeid not in node2name:\n",
    "            node2name[nodeid] = processname\n",
    "    for row in df[(df['object'] == 'process') & (df['action'] != 'create')].itertuples():\n",
    "        nodeid = row.objectID\n",
    "        processname = row.objectname\n",
    "        if nodeid not in node2name:\n",
    "            node2name[nodeid] = processname\n",
    "    # 使用 map 方法将 node2name 字典中的值应用到objectname列\n",
    "    # fillna(df['objectname']) 保证如果没有对应的 nodeid，在不改变原来的值的情况下保持 objectname 原样\n",
    "    df['objectname'] = df['objectID'].map(node2name).fillna(df['objectname'])\n",
    "    df['actorname'] = df['actorID'].map(node2name).fillna(df['actorname'])\n",
    "\n",
    "\n",
    "    new_path = {}\n",
    "    for row in df[(df['object'] == 'file') & (df['action'] == 'rename')].itertuples():\n",
    "        nodeid = row.objectID\n",
    "        new_pathname = row.properties.get('new_path', 'None')\n",
    "        if nodeid not in new_path:\n",
    "            new_path[nodeid] = new_pathname\n",
    "\n",
    "    df['objectname'] = df['objectID'].map(new_path).fillna(df['objectname'])\n",
    "\n",
    "    # 去除重复事件\n",
    "    df.drop_duplicates(subset=['action', 'actorID', 'objectID', 'object', 'actorname', 'objectname', 'pid', 'ppid'], inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # 根据进程名称和pid生成新的索引\n",
    "    for index, row in df.iterrows():\n",
    "        if row['object'] == 'process':\n",
    "            # 对于 'process' 类型\n",
    "            src_id = stringtomd5(row['actorname'] + str(row['ppid']))\n",
    "            dest_id = stringtomd5(row['objectname'] + str(row['pid']))\n",
    "        elif row['object'] in ['flow', 'file', 'module']:\n",
    "            # 对于 'flow' 或 'file' 类型\n",
    "            src_id = stringtomd5(row['actorname'] + str(row['pid']))\n",
    "            dest_id = stringtomd5(row['objectname'])\n",
    "        else:\n",
    "            # 如果其他类型的 object\n",
    "            src_id = None\n",
    "            dest_id = None\n",
    "        \n",
    "        # 将结果存入新的列\n",
    "        df.at[index, 'src_id'] = src_id\n",
    "        df.at[index, 'dest_id'] = dest_id\n",
    "\n",
    "    # 去除重复事件\n",
    "    df.drop_duplicates(subset=['action', 'src_id', 'dest_id', 'object', 'actorname', 'objectname'], inplace=True)\n",
    "    df = df[df['src_id'] != df['dest_id']]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = proprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>actorID</th>\n",
       "      <th>hostname</th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>objectID</th>\n",
       "      <th>pid</th>\n",
       "      <th>ppid</th>\n",
       "      <th>principal</th>\n",
       "      <th>properties</th>\n",
       "      <th>tid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>actorname</th>\n",
       "      <th>objectname</th>\n",
       "      <th>phrase</th>\n",
       "      <th>command_line</th>\n",
       "      <th>src_id</th>\n",
       "      <th>dest_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inbound</td>\n",
       "      <td>0779a248-9269-498e-8ef7-6bbef00e4e03</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>b788899e-52cc-4d6a-9a6f-cc07b5efa8f3</td>\n",
       "      <td>flow</td>\n",
       "      <td>ab16baa4-8596-4143-b018-a2d79a8bbaa0</td>\n",
       "      <td>2276</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '4', 'dest_ip': '225.0.0.1', ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:11:58</td>\n",
       "      <td>python.exe</td>\n",
       "      <td>225.0.0.1-5000</td>\n",
       "      <td>[python.exe, inbound, 225.0.0.1-5000]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c0b7abbed0861c3e8f49286fbd82c079857f8b5de82e97...</td>\n",
       "      <td>2e5184a3ab6979f2edb0508f3e863f7cb8e52a5a538247...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inbound</td>\n",
       "      <td>bde3d89a-41f5-498d-aad7-785c9eb41970</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>da1228f7-5b2a-4d36-b9e7-fb1f2842349e</td>\n",
       "      <td>flow</td>\n",
       "      <td>d983dccd-cdb2-45ea-a0ec-cd016e758459</td>\n",
       "      <td>860</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '4', 'dest_ip': '224.0.0.251'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:12:00</td>\n",
       "      <td>svchost.exe</td>\n",
       "      <td>224.0.0.251-5353</td>\n",
       "      <td>[svchost.exe, inbound, 224.0.0.251-5353]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a9a3cea4cc0842ec70e94fb4bb79ab6f5d9f6e3db87186...</td>\n",
       "      <td>540a960fe00f02eb2e4f3087a04e3c95767d350cfc8fb5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inbound</td>\n",
       "      <td>bde3d89a-41f5-498d-aad7-785c9eb41970</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>5b90fa08-3e00-44ad-8bce-b17ee36222b0</td>\n",
       "      <td>flow</td>\n",
       "      <td>6d615d16-cd6b-4db1-b199-f5522ea09b6d</td>\n",
       "      <td>860</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '4', 'dest_ip': '224.0.0.252'...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:12:00</td>\n",
       "      <td>svchost.exe</td>\n",
       "      <td>224.0.0.252-5355</td>\n",
       "      <td>[svchost.exe, inbound, 224.0.0.252-5355]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a9a3cea4cc0842ec70e94fb4bb79ab6f5d9f6e3db87186...</td>\n",
       "      <td>3141fcdee29e08c16775278065dc82a8a9a02dba73b44f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inbound</td>\n",
       "      <td>bde3d89a-41f5-498d-aad7-785c9eb41970</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>0f40757e-8670-46a6-b1bb-e3170cb3a619</td>\n",
       "      <td>flow</td>\n",
       "      <td>3a390b68-88c0-46bf-8a9d-fb98a97babc8</td>\n",
       "      <td>860</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '1', 'dest_ip': 'ff02::fb', '...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:12:01</td>\n",
       "      <td>svchost.exe</td>\n",
       "      <td>ff02::fb-5353</td>\n",
       "      <td>[svchost.exe, inbound, ff02::fb-5353]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a9a3cea4cc0842ec70e94fb4bb79ab6f5d9f6e3db87186...</td>\n",
       "      <td>e9279d5c69ac1643a5aff74e8c61d79ca87c277c8e44b5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inbound</td>\n",
       "      <td>bde3d89a-41f5-498d-aad7-785c9eb41970</td>\n",
       "      <td>SysClient0501.systemia.com</td>\n",
       "      <td>76c59712-9b02-4491-b9e5-9391816342bf</td>\n",
       "      <td>flow</td>\n",
       "      <td>859ee914-31bf-4162-93a3-ab144e5f4027</td>\n",
       "      <td>860</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>{'acuity_level': '1', 'dest_ip': 'ff02::1:3', ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-09-19 17:12:01</td>\n",
       "      <td>svchost.exe</td>\n",
       "      <td>ff02::1:3-5355</td>\n",
       "      <td>[svchost.exe, inbound, ff02::1:3-5355]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a9a3cea4cc0842ec70e94fb4bb79ab6f5d9f6e3db87186...</td>\n",
       "      <td>772f7bb001ad57b12b71c6d1187e6ff765a2e717c30800...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    action                               actorID                    hostname  \\\n",
       "0  inbound  0779a248-9269-498e-8ef7-6bbef00e4e03  SysClient0501.systemia.com   \n",
       "1  inbound  bde3d89a-41f5-498d-aad7-785c9eb41970  SysClient0501.systemia.com   \n",
       "2  inbound  bde3d89a-41f5-498d-aad7-785c9eb41970  SysClient0501.systemia.com   \n",
       "3  inbound  bde3d89a-41f5-498d-aad7-785c9eb41970  SysClient0501.systemia.com   \n",
       "4  inbound  bde3d89a-41f5-498d-aad7-785c9eb41970  SysClient0501.systemia.com   \n",
       "\n",
       "                                     id object  \\\n",
       "0  b788899e-52cc-4d6a-9a6f-cc07b5efa8f3   flow   \n",
       "1  da1228f7-5b2a-4d36-b9e7-fb1f2842349e   flow   \n",
       "2  5b90fa08-3e00-44ad-8bce-b17ee36222b0   flow   \n",
       "3  0f40757e-8670-46a6-b1bb-e3170cb3a619   flow   \n",
       "4  76c59712-9b02-4491-b9e5-9391816342bf   flow   \n",
       "\n",
       "                               objectID   pid  ppid principal  \\\n",
       "0  ab16baa4-8596-4143-b018-a2d79a8bbaa0  2276    -1             \n",
       "1  d983dccd-cdb2-45ea-a0ec-cd016e758459   860    -1             \n",
       "2  6d615d16-cd6b-4db1-b199-f5522ea09b6d   860    -1             \n",
       "3  3a390b68-88c0-46bf-8a9d-fb98a97babc8   860    -1             \n",
       "4  859ee914-31bf-4162-93a3-ab144e5f4027   860    -1             \n",
       "\n",
       "                                          properties  tid           timestamp  \\\n",
       "0  {'acuity_level': '4', 'dest_ip': '225.0.0.1', ...   -1 2019-09-19 17:11:58   \n",
       "1  {'acuity_level': '4', 'dest_ip': '224.0.0.251'...   -1 2019-09-19 17:12:00   \n",
       "2  {'acuity_level': '4', 'dest_ip': '224.0.0.252'...   -1 2019-09-19 17:12:00   \n",
       "3  {'acuity_level': '1', 'dest_ip': 'ff02::fb', '...   -1 2019-09-19 17:12:01   \n",
       "4  {'acuity_level': '1', 'dest_ip': 'ff02::1:3', ...   -1 2019-09-19 17:12:01   \n",
       "\n",
       "     actorname        objectname                                    phrase  \\\n",
       "0   python.exe    225.0.0.1-5000     [python.exe, inbound, 225.0.0.1-5000]   \n",
       "1  svchost.exe  224.0.0.251-5353  [svchost.exe, inbound, 224.0.0.251-5353]   \n",
       "2  svchost.exe  224.0.0.252-5355  [svchost.exe, inbound, 224.0.0.252-5355]   \n",
       "3  svchost.exe     ff02::fb-5353     [svchost.exe, inbound, ff02::fb-5353]   \n",
       "4  svchost.exe    ff02::1:3-5355    [svchost.exe, inbound, ff02::1:3-5355]   \n",
       "\n",
       "  command_line                                             src_id  \\\n",
       "0          NaN  c0b7abbed0861c3e8f49286fbd82c079857f8b5de82e97...   \n",
       "1          NaN  a9a3cea4cc0842ec70e94fb4bb79ab6f5d9f6e3db87186...   \n",
       "2          NaN  a9a3cea4cc0842ec70e94fb4bb79ab6f5d9f6e3db87186...   \n",
       "3          NaN  a9a3cea4cc0842ec70e94fb4bb79ab6f5d9f6e3db87186...   \n",
       "4          NaN  a9a3cea4cc0842ec70e94fb4bb79ab6f5d9f6e3db87186...   \n",
       "\n",
       "                                             dest_id  \n",
       "0  2e5184a3ab6979f2edb0508f3e863f7cb8e52a5a538247...  \n",
       "1  540a960fe00f02eb2e4f3087a04e3c95767d350cfc8fb5...  \n",
       "2  3141fcdee29e08c16775278065dc82a8a9a02dba73b44f...  \n",
       "3  e9279d5c69ac1643a5aff74e8c61d79ca87c277c8e44b5...  \n",
       "4  772f7bb001ad57b12b71c6d1187e6ff765a2e717c30800...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['object'] != \"module\"]\n",
    "read_df = df[df['action'] == 'read']\n",
    "write_actions = ['write', 'modify', 'create', 'rename']\n",
    "\n",
    "# 筛选出写操作的行，并排除由 system 和 dwm.exe 修改的文件\n",
    "# write_df = df[(df['action'].isin(write_actions)) & (~df['actorname'].isin(['system', 'dwm.exe']))]\n",
    "sys_dwm = df[df['actorname'].isin(['system', 'dwm.exe'])]['dest_id']\n",
    "\n",
    "write_df = df[df['action'].isin(write_actions)]\n",
    "\n",
    "\n",
    "\n",
    "# write_object_ids = set(write_df['dest_id'])\n",
    "write_object_ids = set(write_df['dest_id']) - set(sys_dwm)\n",
    "readonly_df = read_df[~read_df['dest_id'].isin(write_object_ids)]\n",
    "readonly_df_ids = readonly_df['dest_id']\n",
    "df = df[~df['dest_id'].isin(readonly_df_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从df中去除名为\\device\\harddiskvolume1\\windows\\system32\\svchost.exe和\\device\\harddiskvolume1\\windows\\system32\\conhost.exe的节点\n",
    "exclude_values = [\n",
    "    '\\device\\harddiskvolume1\\windows\\system32\\svchost.exe',\n",
    "    '\\device\\harddiskvolume1\\windows\\system32\\conhost.exe',\n",
    "    'svchost.exe',\n",
    "    'consent.exe'\n",
    "]\n",
    "\n",
    "# 过滤掉包含指定值的行\n",
    "df = df[~df['actorname'].isin(exclude_values) & ~df['objectname'].isin(exclude_values)]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到所有 create 操作的父进程和子进程\n",
    "parent_child_df = df[(df['action'] == 'create') & (df['object'] == 'process')]\n",
    "\n",
    "# 提取所有父进程和子进程的 ID\n",
    "parent_ids = set(parent_child_df['src_id'])  # 父进程 ID\n",
    "child_ids = set(parent_child_df['dest_id'])   # 子进程 ID\n",
    "\n",
    "# 所有相关的进程 ID（即有父进程或有子进程的）\n",
    "related_ids = parent_ids.union(child_ids)\n",
    "\n",
    "# 从 df 中移除既没有父进程也没有子进程的节点\n",
    "df = df[df['src_id'].isin(related_ids) | df['dest_id'].isin(related_ids)]\n",
    "\n",
    "# 重置索引\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤掉没有cmdline的进程节点：\n",
    "df = df[~((df['object'] == 'process') & (df['command_line'] == 'none'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# 假设 df 是你的 DataFrame\n",
    "# 1. 筛选 object 列为 'process' 的行\n",
    "df_process = df[df['object'] == 'process']\n",
    "\n",
    "# 2. 创建一个无向图\n",
    "G = nx.Graph()\n",
    "\n",
    "# 3. 添加边 (src_id, dest_id) 到图中\n",
    "for _, row in df_process.iterrows():\n",
    "    G.add_edge(row['src_id'], row['dest_id'])\n",
    "\n",
    "# 4. 获取图中的所有连通子图\n",
    "connected_components = list(nx.connected_components(G))\n",
    "\n",
    "# 5. 过滤掉节点数小于 2 的子图\n",
    "filtered_components = [comp for comp in connected_components if len(comp) > 2]\n",
    "\n",
    "# 6. 获取所有保留的节点\n",
    "valid_nodes = set(node for component in filtered_components for node in component)\n",
    "\n",
    "# 7. 根据 valid_nodes 过滤原 DataFrame 中的行\n",
    "# df_filtered = df_process[df_process['src_id'].isin(valid_nodes) & df_process['dest_id'].isin(valid_nodes)]\n",
    "\n",
    "# 结果：df_filtered 就是筛选后的 DataFrame\n",
    "df = df[(df['src_id'].isin(valid_nodes) | df['dest_id'].isin(valid_nodes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read      222391\n",
       "modify     21692\n",
       "write      20921\n",
       "create     15020\n",
       "delete     12162\n",
       "rename      2229\n",
       "Name: action, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['object'] == 'file']['action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module     521946\n",
       "file       294415\n",
       "flow       107055\n",
       "process     28804\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['object'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['object'] != \"module\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file       294415\n",
       "flow       107055\n",
       "process     28804\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['object'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_df = df[df['action'] == 'read']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_actions = ['write', 'modify', 'create', 'rename']\n",
    "# write_df = df[df['action'].isin(write_actions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_object_ids = set(write_df['dest_id'])\n",
    "# readonly_df = read_df[~read_df['dest_id'].isin(write_object_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readonly_df_ids = readonly_df['dest_id']\n",
    "# df = df[~df['dest_id'].isin(readonly_df_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file       194678\n",
       "flow       107055\n",
       "process     28804\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['object'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into Neo4j.\n"
     ]
    }
   ],
   "source": [
    "df_process_lineage = df[(df['action'] == 'create') & (df['object'] == 'process')]\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "\n",
    "# 创建连接函数\n",
    "def create_connection(uri, user, password):\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create connection: {e}\")\n",
    "        return None\n",
    "\n",
    "# Neo4j 数据库连接信息\n",
    "uri = \"bolt://192.168.115.34:7687\"  # 默认连接 URI\n",
    "user = \"neo4j\"\n",
    "password = \"12345678\"\n",
    "\n",
    "# 创建连接\n",
    "driver = create_connection(uri, user, password)\n",
    "\n",
    "# 插入节点和关系到 Neo4j 的函数（批量插入优化）\n",
    "def insert_nodes_and_relationships(tx, data):\n",
    "    # query = \"\"\"\n",
    "    #     UNWIND $rows AS row\n",
    "    #     CALL apoc.merge.node(['process'], {id: row.actorID}) YIELD node AS src\n",
    "    #     SET src.name = COALESCE(src.name, row.actorname), src.type = 'process'\n",
    "    #     WITH src, row\n",
    "\n",
    "    #     CALL apoc.merge.node([row.object], {id: row.objectID}) YIELD node AS dest\n",
    "    #     SET dest.name = COALESCE(dest.name, row.objectname), dest.type = row.object\n",
    "    #     WITH src, dest, row\n",
    "\n",
    "    #     CALL apoc.create.relationship(src, row.action, {time: row.timestamp, cmdline: row.command_line}, dest) YIELD rel\n",
    "    #     RETURN rel\n",
    "    # \"\"\"\n",
    "    query = \"\"\"\n",
    "        UNWIND $rows AS row\n",
    "        CALL apoc.merge.node(['process'], {id: row.src_id}) YIELD node AS src\n",
    "        SET src.name = COALESCE(src.name, row.actorname), src.type = 'process'\n",
    "        WITH src, row\n",
    "\n",
    "        CALL apoc.merge.node([row.object], {id: row.dest_id}) YIELD node AS dest\n",
    "        SET dest.name = COALESCE(dest.name, row.objectname), dest.type = row.object\n",
    "        WITH src, dest, row\n",
    "\n",
    "        CALL apoc.create.relationship(src, row.action, {time: row.timestamp, cmdline: row.command_line}, dest) YIELD rel\n",
    "        RETURN rel\n",
    "    \"\"\"\n",
    "    tx.run(query, rows=data.to_dict('records'))\n",
    "\n",
    "# 使用 Neo4j 的会话插入数据\n",
    "def load_data_to_neo4j(driver, data):\n",
    "    if not driver:\n",
    "        print(\"No driver available. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            session.write_transaction(insert_nodes_and_relationships, data)\n",
    "        print(\"Data successfully loaded into Neo4j.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data: {e}\")\n",
    "\n",
    "# 示例 DataFrame（假设您已经准备好了df1）\n",
    "# file_path = \"0924_2.csv\"\n",
    "# df1 = pd.read_csv(file_path)\n",
    "# df = df1  # 这里假设 df1 已经定义或载入\n",
    "\n",
    "# 加载数据\n",
    "load_data_to_neo4j(driver, df_process_lineage)\n",
    "\n",
    "# 关闭连接\n",
    "if driver:\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_lineage.to_csv('df_process_lineage2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        model.save('../trained_weights/optc/cmdline_attack2_w2v.model')\n",
    "        self.epoch += 1\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1\n",
    "\n",
    "def prepare_sentences(df):\n",
    "    nodes = {}\n",
    "    for index, row in df.iterrows():\n",
    "        for key in ['src_id', 'dest_id']:\n",
    "            node_id = row[key]\n",
    "            nodes.setdefault(node_id, []).extend(row['phrase'])\n",
    "    return list(nodes.values())\n",
    "\n",
    "def train_word2vec_model(df):\n",
    "    phrases = prepare_sentences(df)\n",
    "\n",
    "    logger = EpochLogger()\n",
    "    saver = EpochSaver()\n",
    "    word2vec = Word2Vec(sentences=phrases, vector_size=64, window=5, min_count=2, workers=8, epochs=50, callbacks=[saver, logger])\n",
    "\n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n",
      "Epoch #10 start\n",
      "Epoch #10 end\n",
      "Epoch #11 start\n",
      "Epoch #11 end\n",
      "Epoch #12 start\n",
      "Epoch #12 end\n",
      "Epoch #13 start\n",
      "Epoch #13 end\n",
      "Epoch #14 start\n",
      "Epoch #14 end\n",
      "Epoch #15 start\n",
      "Epoch #15 end\n",
      "Epoch #16 start\n",
      "Epoch #16 end\n",
      "Epoch #17 start\n",
      "Epoch #17 end\n",
      "Epoch #18 start\n",
      "Epoch #18 end\n",
      "Epoch #19 start\n",
      "Epoch #19 end\n",
      "Epoch #20 start\n",
      "Epoch #20 end\n",
      "Epoch #21 start\n",
      "Epoch #21 end\n",
      "Epoch #22 start\n",
      "Epoch #22 end\n",
      "Epoch #23 start\n",
      "Epoch #23 end\n",
      "Epoch #24 start\n",
      "Epoch #24 end\n",
      "Epoch #25 start\n",
      "Epoch #25 end\n",
      "Epoch #26 start\n",
      "Epoch #26 end\n",
      "Epoch #27 start\n",
      "Epoch #27 end\n",
      "Epoch #28 start\n",
      "Epoch #28 end\n",
      "Epoch #29 start\n",
      "Epoch #29 end\n",
      "Epoch #30 start\n",
      "Epoch #30 end\n",
      "Epoch #31 start\n",
      "Epoch #31 end\n",
      "Epoch #32 start\n",
      "Epoch #32 end\n",
      "Epoch #33 start\n",
      "Epoch #33 end\n",
      "Epoch #34 start\n",
      "Epoch #34 end\n",
      "Epoch #35 start\n",
      "Epoch #35 end\n",
      "Epoch #36 start\n",
      "Epoch #36 end\n",
      "Epoch #37 start\n",
      "Epoch #37 end\n",
      "Epoch #38 start\n",
      "Epoch #38 end\n",
      "Epoch #39 start\n",
      "Epoch #39 end\n",
      "Epoch #40 start\n",
      "Epoch #40 end\n",
      "Epoch #41 start\n",
      "Epoch #41 end\n",
      "Epoch #42 start\n",
      "Epoch #42 end\n",
      "Epoch #43 start\n",
      "Epoch #43 end\n",
      "Epoch #44 start\n",
      "Epoch #44 end\n",
      "Epoch #45 start\n",
      "Epoch #45 end\n",
      "Epoch #46 start\n",
      "Epoch #46 end\n",
      "Epoch #47 start\n",
      "Epoch #47 end\n",
      "Epoch #48 start\n",
      "Epoch #48 end\n",
      "Epoch #49 start\n",
      "Epoch #49 end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7420203c3850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word2vec_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程见optc_parser3\n",
    "word2vec_weights = '../trained_weights/optc/cmdline_attack2_w2v.model'\n",
    "w2vmodel = Word2Vec.load(word2vec_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inbound     80890\n",
       "create      28065\n",
       "outbound    14640\n",
       "read        14058\n",
       "modify      11968\n",
       "write       10492\n",
       "delete       7076\n",
       "rename       1429\n",
       "Name: action, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def infer(word):\n",
    "    if word in  w2vmodel.wv:\n",
    "        word_embeddings = w2vmodel.wv[word]\n",
    "    else:\n",
    "        word_embeddings = np.zeros(64)\n",
    "\n",
    "    output_embedding = torch.tensor(word_embeddings, dtype=torch.float)\n",
    "    output_embedding = output_embedding.detach().cpu().numpy()\n",
    "    return output_embedding\n",
    "\n",
    "\n",
    "def Featurize(df):\n",
    "    # dummies = {'process': 0, 'flow': 1, 'file': 2, 'module': 3}\n",
    "    dummies = {'process': 0, 'flow': 1, 'file': 2}\n",
    "\n",
    "    nodes = {}\n",
    "    labels = {}\n",
    "    lblmap = {}\n",
    "    neimap = {}\n",
    "    edges = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        actor_id, object_id = row['src_id'], row[\"dest_id\"]\n",
    "        object_type = row['object']\n",
    "\n",
    "        if actor_id not in nodes:\n",
    "            nodes[actor_id] = row['actorname']\n",
    "        if object_id not in nodes:\n",
    "            nodes[object_id] = row['objectname']\n",
    "\n",
    "        # nodes.setdefault(actor_id, []).extend(row['phrase'])\n",
    "        # nodes.setdefault(object_id, []).extend(row['phrase'])\n",
    "\n",
    "        labels[actor_id] = dummies.get('process', -1)\n",
    "        labels[object_id] = dummies.get(object_type, -1)\n",
    "\n",
    "        if actor_id not in lblmap:\n",
    "            lblmap[actor_id] = row['actorname']\n",
    "        if object_id not in lblmap:\n",
    "            lblmap[object_id] = row['objectname']\n",
    "\n",
    "        neimap.setdefault(actor_id, set()).add(row['objectname'])\n",
    "        neimap.setdefault(object_id, set()).add(row['actorname'])\n",
    "\n",
    "        edge_type = row['action']\n",
    "        edges.append((actor_id, object_id, edge_type))\n",
    "\n",
    "    features, feat_labels, edge_index = [], [], [[], []]\n",
    "    node_index = {}\n",
    "\n",
    "    for node, nodename in nodes.items():\n",
    "        features.append(infer(nodename))\n",
    "        feat_labels.append(labels[node])\n",
    "        node_index[node] = len(features) - 1\n",
    "\n",
    "    for src, dst, action in edges:\n",
    "        if action=='read' or action=='inbound':\n",
    "            edge_index[0].append(node_index[dst])\n",
    "            edge_index[1].append(node_index[src])\n",
    "        elif action=='create':\n",
    "            edge_index[0].append(node_index[src])\n",
    "            edge_index[1].append(node_index[dst])\n",
    "            edge_index[0].append(node_index[dst])\n",
    "            edge_index[1].append(node_index[src])\n",
    "        else:\n",
    "            edge_index[0].append(node_index[src])\n",
    "            edge_index[1].append(node_index[dst])\n",
    "\n",
    "    mapp = list(node_index.keys())\n",
    "\n",
    "    return features, np.array(feat_labels), edge_index, mapp, lblmap, neimap\n",
    "\n",
    "nodes,labels,edges,mapp,lbl,nemap = Featurize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50558, 50558, 50558)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes),len(labels),len(mapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个字典，存储每个节点对应的特征向量\n",
    "nodes_vec = {}\n",
    "for i, j in zip(mapp, nodes):\n",
    "    nodes_vec[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交换源节点和目标节点，因为信息汇聚是由源节点汇聚到目标节点\n",
    "# edges[0], edges[1] = edges[1], edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\windows\\\\system32\\\\cmd.exe /c \"schtasks /query /tn \"kickoffautologinrandom\"\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['object'] == 'process']['command_line'].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.1710038 ,  2.2176752 , -2.8056862 , -0.13410376, -2.4889944 ,\n",
       "        1.2847246 ,  0.81249833,  1.6076974 , -0.820968  , -0.1124811 ,\n",
       "       -1.1579026 , -4.3741226 ,  2.4518425 , -2.009511  ,  1.8991797 ,\n",
       "        1.3965123 ,  0.4279191 , -1.0794978 ,  0.8141694 ,  3.280765  ,\n",
       "       -1.0856953 , -1.771491  , -4.606667  ,  0.41917223, -0.39464146,\n",
       "       -2.1049082 ,  2.1203058 ,  0.01671414,  1.2729584 ,  1.3268495 ,\n",
       "       -0.03292276, -2.0943627 , -1.9548821 ,  1.7422594 , -2.4182568 ,\n",
       "       -3.530913  ,  2.5135503 , -4.5729566 , -1.9743692 , -0.00655073,\n",
       "        0.06188334, -2.3398387 ,  3.1908853 , -0.91746294, -1.863292  ,\n",
       "        0.7778305 , -0.1308581 , -0.81006503,  3.4177716 , -1.2763164 ,\n",
       "        0.60874236,  3.077225  , -0.72015214, -0.6682652 ,  0.07476221,\n",
       "       -0.906641  ,  2.9538078 , -0.23001549,  0.5157899 ,  3.5763273 ,\n",
       "       -2.0665421 ,  0.22892691,  2.935864  ,  0.24647792], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer('schtasks  /query /tn \"kickoffautologinrandom\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从df中去除名为\\device\\harddiskvolume1\\windows\\system32\\svchost.exe和\\device\\harddiskvolume1\\windows\\system32\\conhost.exe的节点\n",
    "# exclude_values = [\n",
    "#     '\\device\\harddiskvolume1\\windows\\system32\\svchost.exe',\n",
    "#     '\\device\\harddiskvolume1\\windows\\system32\\conhost.exe',\n",
    "#     'svchost.exe',\n",
    "#     'consent.exe'\n",
    "# ]\n",
    "\n",
    "# # 过滤掉包含指定值的行\n",
    "# df = df[~df['actorname'].isin(exclude_values) & ~df['objectname'].isin(exclude_values)]\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lowest_ancestor_find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_lineage = df[(df['action'] == 'create') & (df['object'] == 'process')]\n",
    "\n",
    "# 记录每个进程的父进程及其时间戳和 cmdline 信息\n",
    "process_parents = {}\n",
    "\n",
    "# 进程谱系树生成\n",
    "import networkx as nx\n",
    "\n",
    "g = nx.MultiDiGraph()\n",
    "node_map = {}\n",
    "# count_node = 0\n",
    "for index, row in df_process_lineage.iterrows():\n",
    "    src, source_name, dst, dstname, etype, object_type = row['src_id'], row[\"actorname\"],  row['dest_id'], row['objectname'], row['action'], row['object']\n",
    "    command_line = row['command_line']\n",
    "    if src not in node_map:\n",
    "        node_map[src] = src\n",
    "        g.add_node(src, type=\"process\", pname=source_name)\n",
    "    \n",
    "    if dst not in node_map:\n",
    "        node_map[dst] = dst\n",
    "        if source_name==dstname:\n",
    "            g.add_node(dst, type=object_type, pname=dstname)\n",
    "        else:\n",
    "            g.add_node(dst, type=object_type, pname=dstname)\n",
    "    \n",
    "    if g.has_edge(node_map[dst], node_map[src]):\n",
    "        pass\n",
    "    else:\n",
    "        if g.has_edge(node_map[src], node_map[dst]):\n",
    "            pass\n",
    "        elif etype=='create':\n",
    "            g.add_edge(node_map[src], node_map[dst], type=etype, commandline=command_line)\n",
    "        else:\n",
    "            pass\n",
    "    if dst not in process_parents:\n",
    "        process_parents[dst] = []\n",
    "    process_parents[dst].append((src, command_line))\n",
    "\n",
    "def find_lowest_common_ancestor(graph, target_pid):\n",
    "    \"\"\"\n",
    "    查找某个进程的具有多个子进程的最低祖先。\n",
    "    :param graph: NetworkX图对象\n",
    "    :param target_pid: 目标进程ID\n",
    "    :return: 具有多个子进程的最低祖先进程ID\n",
    "    \"\"\"\n",
    "    # 获取目标进程的父进程\n",
    "    def get_parent(pid):\n",
    "        parents = process_parents.get(pid, [])\n",
    "        if parents:\n",
    "            return parents[0][0]  # 假设每个进程有一个父进程\n",
    "        return None\n",
    "    \n",
    "    # 遍历并查找具有多个子进程的父进程\n",
    "    def has_multiple_children(pid):\n",
    "        children = list(graph.successors(pid))\n",
    "        return len(children) > 1  # 如果父进程有多个子进程\n",
    "    \n",
    "    # 从目标进程开始，逐步向上遍历父进程\n",
    "    current_pid = target_pid\n",
    "    \n",
    "    while True:\n",
    "        parent_pid = get_parent(current_pid)\n",
    "        if parent_pid is None:\n",
    "            return None  # 找不到父进程，说明已经是根节点\n",
    "        if has_multiple_children(parent_pid):\n",
    "            # return parent_pid\n",
    "            return current_pid  # 找到具有多个子进程的最低祖先\n",
    "        current_pid = parent_pid  # 向上查找父进程\n",
    "\n",
    "# 存储每个进程的最低祖先\n",
    "process_lca_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "# 遍历所有进程，查找其最低祖先并存储\n",
    "for node in g.nodes:\n",
    "    lca = find_lowest_common_ancestor(g, node)\n",
    "    if lca is not None:\n",
    "        process_lca_dict[node] = process_parents.get(lca, 'meiyou')[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9844"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process c3c2ee2eb8bc61dce7bb2075785780f97ccdbf170f374281cceec8b4c2e5be49's lowest ancestor with multiple children: c3c2ee2eb8bc61dce7bb2075785780f97ccdbf170f374281cceec8b4c2e5be49\n"
     ]
    }
   ],
   "source": [
    "# 示例使用\n",
    "process_id = 'c3c2ee2eb8bc61dce7bb2075785780f97ccdbf170f374281cceec8b4c2e5be49'  # 例如，查找进程 '1006' 的最低祖先\n",
    "ancestor = find_lowest_common_ancestor(g, process_id)\n",
    "if ancestor:\n",
    "    print(f\"Process {process_id}'s lowest ancestor with multiple children: {ancestor}\")\n",
    "else:\n",
    "    print(f\"Process {process_id} has no ancestor with multiple children.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\windows\\system32\\cmd.exe /c \"c:\\windows\\sysnative\\qwinsta.exe bantonio /server 142.20.61.196\"\n"
     ]
    }
   ],
   "source": [
    "print(process_lca_dict.get('c3c2ee2eb8bc61dce7bb2075785780f97ccdbf170f374281cceec8b4c2e5be49'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果一个进程没有父进程，那么他的根节点是open他的进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(process_lca_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GNNWithRootEmbedding(nn.Module):\n",
    "    def __init__(self, num_features, process_lca_dict, node_id_to_hash, node_hash_to_vec):\n",
    "        super(GNNWithRootEmbedding, self).__init__()\n",
    "        \n",
    "        self.node_hash_to_vec = node_hash_to_vec # 存储节点的uuid到其初始向量的映射，其中uuid是hash值\n",
    "        self.node_id_to_hash = node_id_to_hash # 存储节点的batch.n_id到节点uuid的映射，其中batch.n_id的数值，例如1，2，3，其中uuid是hash值\n",
    "        self.process_lca_dict = process_lca_dict  # 存储节点与其根节点ID的映射\n",
    "        self.num_features = num_features  # 节点特征维度\n",
    "        \n",
    "        # 第一层图卷积，输入维度为特征 + 根节点特征维度\n",
    "        self.conv1 = SAGEConv(num_features, 128, normalize=True)  # 用于邻居节点特征的聚合\n",
    "        # 第二层图卷积\n",
    "        self.conv2 = SAGEConv(128, 64, normalize=True)\n",
    "        \n",
    "        # 用于根节点特征的变换矩阵W2\n",
    "        self.root_transform = nn.Linear(num_features, 128)\n",
    "        # 用于根节点特征的变换矩阵W3\n",
    "        self.root_transform2 = nn.Linear(128, 64)\n",
    "\n",
    "        self.linear = nn.Linear(64, 3)\n",
    "    \n",
    "    def root_embedding(self, node_ids):\n",
    "        \"\"\"\n",
    "        通过根节点映射字典，直接获取根节点的特征。\n",
    "        :param node_ids: 当前批次中的节点ID\n",
    "        :return: 返回每个节点对应的根节点嵌入特征\n",
    "        \"\"\"\n",
    "        # 获取节点对应的hash值\n",
    "        node_hash = [self.node_id_to_hash[node_id] for node_id in node_ids]\n",
    "        # 获取节点对应的根节点特征（通过process_lca_dict获得根节点ID）\n",
    "        root_ids = [self.process_lca_dict.get(node_id, \"meiyougengjiedian\") for node_id in node_hash]\n",
    "        \n",
    "        # 在这里你可以调用任意方法返回根节点的特征\n",
    "        # 假设根节点特征向量已经通过某种方式计算并存储，返回对应的特征\n",
    "        # get_origin_embedding 函数假设返回根节点的嵌入特征\n",
    "        # return torch.stack([torch.tensor(self.node_hash_to_vec.get(root_id, torch.zeros(self.num_features))) for root_id in root_ids], dim=0)\n",
    "        return torch.stack([torch.tensor(infer(root_id), dtype=torch.float) for root_id in root_ids], dim=0)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_node_ids):\n",
    "\n",
    "        x = self.encode(x, edge_index, batch_node_ids)\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return F.softmax(x, dim=1)\n",
    "        \n",
    "    def encode(self, x, edge_index, batch_node_ids):\n",
    "        \"\"\"\n",
    "        :param x: 节点特征矩阵\n",
    "        :param edge_index: 边索引\n",
    "        :param batch_node_ids: 当前批次的节点ID\n",
    "        \"\"\"\n",
    "        # 获取当前批次节点的根节点特征\n",
    "        root_embeds = self.root_embedding(batch_node_ids)\n",
    "\n",
    "        # 第一步，聚合邻居特征\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # 第二步，计算根节点特征的影响，根节点特征通过线性变换 W2\n",
    "        root_embeds_transformed = self.root_transform(root_embeds.to(device))\n",
    "        root_embeds_transformed = F.relu(root_embeds_transformed)\n",
    "        root_embeds_transformed = F.dropout(root_embeds_transformed, p=0.2, training=self.training)\n",
    "\n",
    "        # 最后，邻居特征加上根节点变换后的特征\n",
    "        x = x + root_embeds_transformed\n",
    "\n",
    "        # 第二层图卷积\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "\n",
    "        root_embeds_transformed2 = self.root_transform2(root_embeds_transformed)\n",
    "        root_embeds_transformed2 = F.relu(root_embeds_transformed2)\n",
    "        root_embeds_transformed2 = F.dropout(root_embeds_transformed2, p=0.2, training=self.training)\n",
    "\n",
    "        x = x + root_embeds_transformed2\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "model = GNNWithRootEmbedding(64, process_lca_dict, mapp, nodes_vec).to(device)\n",
    "# if not gnnTrain:\n",
    "#     model.load_state_dict(torch.load(gnn_weights))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "l = np.array(labels)\n",
    "class_weights = class_weight.compute_class_weight(class_weight = \"balanced\",classes = np.unique(l),y = l)\n",
    "class_weights = torch.tensor(class_weights,dtype=torch.float).to(device)\n",
    "criterion = CrossEntropyLoss(weight=class_weights,reduction='mean')\n",
    "\n",
    "graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NeighborLoader(graph, num_neighbors=[-1, -1], batch_size=5000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(batch.x, batch.edge_index, batch.n_id)[:batch.batch_size]\n",
    "    y = batch.y[:batch.batch_size]\n",
    "    loss = criterion(predictions, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), batch.batch_size\n",
    "\n",
    "def evaluate_model(batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(batch.x, batch.edge_index, batch.n_id)[:batch.batch_size]\n",
    "        pred_labels = predictions.argmax(dim=1)\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        correct_predictions = int((pred_labels == y).sum())\n",
    "    return correct_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_weights = \"../trained_weights/optc/cmdline_attack2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0. Training Loss: 0.00013, Accuracy: 0.98910\n",
      "Epoch #1. Training Loss: 0.00012, Accuracy: 0.99193\n",
      "Epoch #2. Training Loss: 0.00012, Accuracy: 0.99403\n",
      "Epoch #3. Training Loss: 0.00012, Accuracy: 0.99551\n",
      "Epoch #4. Training Loss: 0.00012, Accuracy: 0.99488\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    total_loss = total_correct = total_nodes = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        # print(batch.x.shape)\n",
    "        loss, num_nodes = train_model(batch)\n",
    "        total_loss += loss\n",
    "        total_nodes += num_nodes\n",
    "        total_correct += evaluate_model(batch)\n",
    "\n",
    "    average_loss = total_loss / total_nodes\n",
    "    accuracy = total_correct / total_nodes\n",
    "\n",
    "    print(f\"Epoch #{epoch}. Training Loss: {average_loss:.5f}, Accuracy: {accuracy:.5f}\")\n",
    "torch.save(model.state_dict(), gnn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cch_TFE_GNN",
   "language": "python",
   "name": "cch_tfe_gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
